{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "090b55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import testutility as util\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2214645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://dahiti.dgfi.tum.de/api/v1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5836c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n",
      "column name and column length validation passed\n"
     ]
    }
   ],
   "source": [
    "# naming convention for the data is: {id}_{river_name}_{lat}_{lon}.csv\n",
    "args = {}\n",
    "\"\"\" required options/credentials \"\"\"\n",
    "args['username'] = 'mussieberhane'\n",
    "args['password'] = 'Westfieldshoehouse6'\n",
    "args['action'] = 'download-water-level'\n",
    "\n",
    "config=util.read_config_file('config.yaml')\n",
    "\n",
    "# Sava River data sets\n",
    "sava_data_ids=config['data_ids']\n",
    "for i in sava_data_ids:\n",
    "\n",
    "    args['dahiti_id']=str(i)\n",
    "    \"\"\" send request as method POST \"\"\"\n",
    "    response = requests.post(url, data=args)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        \"\"\" convert json string into csv file \"\"\"\n",
    "        data = json.loads(response.text)\n",
    "        data=data['target']\n",
    "        latitude=data['latitude']\n",
    "        longitude=data['longitude']\n",
    "        river_name=data['target_name'].split(',')[0]\n",
    "        df=pd.json_normalize(data, 'data')\n",
    "        df.drop('data_type', axis=1, inplace=True)\n",
    "        \n",
    "#         standardise dataframe column names\n",
    "        util.col_header_val(df, config)\n",
    "        \n",
    "#       save csv files in the data directory\n",
    "        os.chdir('../../data/task1-data-collection/')\n",
    "        df.to_csv(args['dahiti_id']+'_'+river_name+'_'+ str(latitude)+'_'+str(longitude)+'_'+'.csv', index=False)\n",
    "    else:\n",
    "        print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f939b7a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
